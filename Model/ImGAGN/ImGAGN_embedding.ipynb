{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from igraph import Graph\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.nn import ModuleList\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import (v_measure_score, homogeneity_score, completeness_score)\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.parameter import Parameter\n",
    "import scipy.sparse as sp\n",
    "from torch.nn.modules.module import Module\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import math\n",
    "import neptune\n",
    "import os\n",
    "import random\n",
    "\n",
    "seed=42\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[6048, 20], edge_index=[2, 20697], y=[6048])\n"
     ]
    }
   ],
   "source": [
    "seed=42\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "graphml_file_path = r'Data/Network/ImGAGN_graph_tclin.graphml'  # Replace according to labels\n",
    "g = ig.Graph.Read_GraphML(graphml_file_path)\n",
    "\n",
    "# Extract node features, labels, and names\n",
    "features = []\n",
    "labels = []\n",
    "for vertex in g.vs:\n",
    "    labels.append(vertex['label'])\n",
    "    vertex_features = []\n",
    "    for attribute in vertex.attributes():\n",
    "        if attribute not in ['name', 'label']:\n",
    "            try:\n",
    "                value = float(vertex[attribute])  # Convert attribute to float\n",
    "            except ValueError:\n",
    "                value = 0.0  # Default value if conversion fails\n",
    "            vertex_features.append(value)\n",
    "    features.append(vertex_features)\n",
    "\n",
    "# Convert features and labels to tensors\n",
    "features_tensor = torch.tensor(features, dtype=torch.float)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Convert the edge list to the format required by PyTorch Geometric\n",
    "edges = g.get_edgelist()\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create the PyTorch Geometric Data object\n",
    "data = Data(x=features_tensor, edge_index=edge_index, y=labels_tensor)\n",
    "\n",
    "print(data)\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def add_edges(adj_real, adj_new):\n",
    "    adj = adj_real+adj_new\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "    return adj\n",
    "\n",
    "def accuracy(output, labels, output_AUC):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "\n",
    "    confusion_mat = confusion_matrix(labels, preds)\n",
    "\n",
    "    recall = recall_score(labels.cpu().numpy(), preds.cpu().numpy(), zero_division=0)\n",
    "    f1_score_ = f1_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
    "    AUC = roc_auc_score(labels.cpu().numpy(), output_AUC.detach().cpu().numpy())\n",
    "    acc = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
    "    precision = precision_score(labels.cpu().numpy(), preds.cpu().numpy(), zero_division=0)\n",
    "    return recall, f1_score_, AUC, acc, precision, confusion_mat\n",
    "\n",
    "def load_data(data, ratio_generated):\n",
    "    print('Processing graph data...')\n",
    "    global idx_train, idx_test\n",
    "    # Extract features and labels from the PyTorch Geometric Data object\n",
    "    features = data.x\n",
    "    labels = data.y\n",
    "\n",
    "    # Convert train and test edge indices to standard numpy arrays for processing\n",
    "    idx_train = idx_train\n",
    "    idx_train = idx_train\n",
    "    # The rest of the code remains largely the same as in your original function\n",
    "    majority = np.array([x for x in idx_train if labels[x] == 0])\n",
    "    minority = np.array([x for x in idx_train if labels[x] == 1])\n",
    "\n",
    "    num_minority = minority.shape[0]\n",
    "    num_majority = majority.shape[0]\n",
    "    print(\"Number of majority: \", num_majority)\n",
    "    print(\"Number of minority: \", num_minority)\n",
    "\n",
    "    generate_node = []\n",
    "    generate_label = []\n",
    "    for i in range(len(labels), len(labels) + int(ratio_generated * num_majority) - num_minority):\n",
    "        generate_node.append(i)\n",
    "        generate_label.append(1)\n",
    "    idx_train = np.hstack((idx_train, np.array(generate_node)))\n",
    "\n",
    "    minority_test = np.array([x for x in idx_test if labels[x] == 1])\n",
    "    minority_all = np.hstack((minority, minority_test))\n",
    "\n",
    "    labels = np.hstack((labels, np.array(generate_label)))\n",
    "\n",
    "    # Construct adjacency matrix from PyTorch Geometric Data\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    adj_real = sp.coo_matrix((np.ones(edge_index.shape[1]), (edge_index[0], edge_index[1])), \n",
    "                             shape=(len(labels), len(labels)), dtype=np.float32)\n",
    "\n",
    "    adj = adj_real + adj_real.T.multiply(adj_real.T > adj_real) - adj_real.multiply(adj_real.T > adj_real)\n",
    "\n",
    "    # Normalizing features and adjacency matrix\n",
    "    features = normalize(sp.csr_matrix(features))\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    labels = torch.LongTensor(labels)\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "    generate_node = torch.LongTensor(np.array(generate_node))\n",
    "    minority = torch.LongTensor(minority)\n",
    "    majority = torch.LongTensor(majority)\n",
    "    minority_all = torch.LongTensor(minority_all)\n",
    "\n",
    "    return adj, adj_real, features, labels, idx_train, idx_test, generate_node, minority, majority, minority_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, nfeat, layer_channels, nclass, dropout, generate_node, min_node):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        \n",
    "        self.convs = ModuleList()\n",
    "\n",
    "        # Add the input layer\n",
    "        self.convs.append(SAGEConv(nfeat, layer_channels[0]))\n",
    "        for i in range(1, len(layer_channels)):\n",
    "            self.convs.append(SAGEConv(layer_channels[i-1], layer_channels[i]))\n",
    "            \n",
    "        self.gc_nclass = SAGEConv(layer_channels[-1], nclass)\n",
    "        self.gc_2 = SAGEConv(layer_channels[-1], 2)\n",
    "        self.attention = Attention(nfeat*2, 1)  # Custom attention mechanism, make sure to define or adapt it\n",
    "        self.generate_node = generate_node\n",
    "        self.min_node = min_node\n",
    "        self.dropout = dropout\n",
    "        self.eps = 1e-10\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        if adj.is_sparse:\n",
    "            # If adj is already a sparse tensor, directly use the indices\n",
    "            edge_index = adj._indices()\n",
    "        else:\n",
    "            # If adj is a dense tensor, convert it to a sparse format\n",
    "            edge_index, _ = dense_to_sparse(adj)\n",
    "\n",
    "        for layer in self.convs:\n",
    "            x = F.relu(layer(x, edge_index))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    " \n",
    "        x1 = self.gc_nclass(x, edge_index)\n",
    "        x2 = self.gc_2(x, edge_index)\n",
    "        return F.log_softmax(x1, dim=1), F.log_softmax(x2, dim=1), F.softmax(x1, dim=1)[:,-1]\n",
    "\n",
    "    def get_embedding(self, x, adj):\n",
    "        if adj.is_sparse:\n",
    "            # If adj is already a sparse tensor, directly use the indices\n",
    "            edge_index = adj._indices()\n",
    "        else:\n",
    "            # If adj is a dense tensor, convert it to a sparse format\n",
    "            edge_index, _ = dense_to_sparse(adj)\n",
    "        for layer in self.convs:\n",
    "            x = F.relu(layer(x, edge_index))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, output_dim, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,  dim):\n",
    "        super(Generator, self).__init__( )\n",
    "\n",
    "        self.fc1 = nn.Linear(100, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, dim)\n",
    "        self.fc4 = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = (x+1)/2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, adj):\n",
    "    global max_recall, test_recall, test_f1, test_AUC, test_acc, test_pre, confusion\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output, output_gen, output_AUC = model(features, adj)\n",
    "\n",
    "    labels_true = torch.cat((torch.LongTensor(num_real).fill_(0), torch.LongTensor(num_false).fill_(1)))\n",
    "\n",
    "    if cuda:\n",
    "        labels_true=labels_true.cuda()\n",
    "\n",
    "    loss_dis = - euclidean_dist(features[minority], features[majority]).mean()\n",
    "    #F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    loss_train =  F.nll_loss(output[idx_train], labels[idx_train]) + F.nll_loss(output_gen[idx_train], labels_true) + loss_dis\n",
    "\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if not fastmode:\n",
    "        model.eval()\n",
    "        output, output_gen, output_AUC = model(features, adj)\n",
    "\n",
    "\n",
    "    recall_val, f1_val, AUC_val, acc_val, pre_val, conf_val = accuracy(output[idx_val], labels[idx_val], output_AUC[idx_val])\n",
    "    recall_train, f1_train, AUC_train, acc_train, pre_train, conf_train = accuracy(output[idx_val], labels[idx_val], output_AUC[idx_val])\n",
    "\n",
    "    output, output_gen, output_AUC = model(features, adj)\n",
    "    recall_tmp, f1_tmp, AUC_tmp, acc_tmp, pre_tmp, conf = accuracy(output[idx_test], labels[idx_test], output_AUC[idx_test])\n",
    "    test_recall = recall_tmp\n",
    "    test_f1 = f1_tmp\n",
    "    test_AUC = AUC_tmp\n",
    "    test_acc = acc_tmp\n",
    "    test_pre = pre_tmp\n",
    "    max_recall = (recall_val + acc_val)/2\n",
    "    confusion = conf\n",
    "\n",
    "    return test_recall, test_pre, test_f1, test_AUC, test_acc, confusion, loss_train\n",
    "\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n",
    "    yy = torch.pow(y, 2).sum(1, keepdim=True).expand(n, m).t()\n",
    "    dist = xx + yy\n",
    "    dist.addmm_(1, -2, x, y.t())\n",
    "    dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4233,) (1815,)\n"
     ]
    }
   ],
   "source": [
    "seed=42\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "targets = np.array([x for x in range(6048) if data.y[x] == 1])\n",
    "ntargets = np.array([x for x in range(6048) if data.y[x] == 0])\n",
    "\n",
    "targets_train, targets_test, train_label_1, test_label_1 = train_test_split(targets, np.ones(len(targets)), test_size=0.3)\n",
    "ntargets_train, ntargets_test, train_label_0,test_label_0 = train_test_split(ntargets, np.zeros(len(ntargets)), test_size=0.3)\n",
    "\n",
    "idx_train = np.concatenate((np.array(targets_train),np.array(ntargets_train)))\n",
    "idx_test = np.concatenate((ntargets_test, targets_test))\n",
    "\n",
    "idx_train_origin = idx_train\n",
    "print(idx_train.shape, idx_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing graph data...\n",
      "Number of majority:  4167\n",
      "Number of minority:  66\n",
      "torch.Size([10149, 10149]) (10149, 10149) torch.Size([6048, 20]) torch.Size([10149]) torch.Size([8334]) torch.Size([1815]) torch.Size([4101]) torch.Size([66]) torch.Size([4167]) torch.Size([95])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/2qpq4bz50bj2bq5zmw8dnkd00000gn/T/ipykernel_32144/1104360825.py:3: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/georgewang2008/ImGAGN/e/IM-118\n",
      "g_loss= Epoch: 0001 recall= 1.00000 precision= 0.01728 f1= 0.03398 AUC= 0.67661 ACC= 0.09146\n",
      "g_loss= Epoch: 0002 recall= 0.79310 precision= 0.02419 f1= 0.04694 AUC= 0.70168 ACC= 0.48540\n",
      "g_loss= Epoch: 0003 recall= 0.27586 precision= 0.03008 f1= 0.05424 AUC= 0.73126 ACC= 0.84628\n",
      "g_loss= Epoch: 0004 recall= 0.10345 precision= 0.01987 f1= 0.03333 AUC= 0.74984 ACC= 0.90413\n",
      "g_loss= Epoch: 0005 recall= 0.06897 precision= 0.02273 f1= 0.03419 AUC= 0.75507 ACC= 0.93774\n",
      "\n",
      "final_test\n",
      "\n",
      "Test Recall:  0.06896551724137931\n",
      "Test Accuracy:  0.9377410468319559\n",
      "Test F1:  0.03418803418803419\n",
      "Test precision:  0.022727272727272728\n",
      "Test AUC:  0.7550681546125034\n",
      "[[1700   86]\n",
      " [  27    2]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#hyper parameters#################\n",
    "#################################\n",
    "#################################\n",
    "\n",
    "#Tclin hype\n",
    "ratio = 1\n",
    "layer_channels = [40, 80, 80]\n",
    "dropout = 0.3 #0.2, 0.25, 0.3, 0.4, 0.5\n",
    "lr = 0.005\n",
    "weight_decay = 0.0004   #0.0003, 0.0004, 0.0005, 0.0007, 0.0009, 0.001, 0.002, 0.003\n",
    "fastmode = False\n",
    "no_cuda = False\n",
    "num= 10\n",
    "seed= 42\n",
    "epochs_gen = 13\n",
    "epochs = 20 #25, 30, 20\n",
    "alpha = 0.2\n",
    "\n",
    "\n",
    "'''\n",
    "#Pancreatic hype\n",
    "ratio = 1\n",
    "layer_channels = [40, 80, 80]\n",
    "dropout = 0.7 #0.2, 0.25, 0.3, 0.4, 0.5\n",
    "lr = 0.0007\n",
    "weight_decay = 0.001   #0.0003, 0.0004, 0.0005, 0.0007, 0.0009, 0.001, 0.002, 0.003\n",
    "fastmode = False\n",
    "no_cuda = False\n",
    "num= 10\n",
    "seed= 42\n",
    "epochs_gen = 5\n",
    "epochs = 25 #25, 30, 20\n",
    "alpha = 0.2\n",
    "\n",
    "\n",
    "\n",
    "#Leukemia\n",
    "ratio = 1\n",
    "layer_channels = [40, 80, 80]\n",
    "dropout = 0.7 #0.2, 0.25, 0.3, 0.4, 0.5\n",
    "lr = 0.002\n",
    "weight_decay = 0.001   #0.0003, 0.0004, 0.0005, 0.0007, 0.0009, 0.001, 0.002, 0.003\n",
    "fastmode = False\n",
    "no_cuda = False\n",
    "num= 10\n",
    "seed= 42\n",
    "epochs_gen = 27\n",
    "epochs = 25 #25, 30, 20\n",
    "alpha = 0.2\n",
    "'''\n",
    "###############################\n",
    "###############################\n",
    "###############################\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "adj, adj_real, features, labels, idx_temp, idx_test, generate_node, minority, majority, minority_all = load_data(data, ratio)\n",
    "\n",
    "print(adj.shape, adj_real.shape, features.shape, labels.shape, idx_temp.shape, idx_test.shape, generate_node.shape, minority.shape, majority.shape, minority_all.shape)\n",
    "\n",
    "\n",
    "model = GraphSAGE(nfeat=features.shape[1],\n",
    "    layer_channels = layer_channels,\n",
    "    nclass=labels.max().item() + 1,\n",
    "    dropout=dropout,\n",
    "    generate_node= generate_node,\n",
    "    min_node = minority)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "num_false = labels.shape[0]- features.shape[0]\n",
    "model_generator = Generator(minority_all.shape[0])\n",
    "optimizer_G = torch.optim.Adam(model_generator.parameters(),\n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "max_recall = 0\n",
    "test_recall = 0\n",
    "test_f1 = 0\n",
    "test_AUC = 0\n",
    "test_acc=0\n",
    "test_pre =0\n",
    "confusion = 0 \n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_temp = idx_temp.cuda()\n",
    "    idx_test = idx_test.cuda()\n",
    "    model_generator.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch_gen in range(epochs_gen):\n",
    "    part = epoch_gen % num\n",
    "    range_val_maj = range(int(part*len(majority)/num), int((part+1)*len(majority)/num))\n",
    "    range_val_min = range(int(part * len(minority) / num), int((part + 1) * len(minority) / num))\n",
    "\n",
    "    range_train_maj = list(range(0,int(part*len(majority)/num)))+ list(range(int((part+1)*len(majority)/num),len(majority)))\n",
    "    range_train_min = list(range(0,int(part*len(minority)/num)))+ list(range(int((part+1)*len(minority)/num),len(minority)))\n",
    "\n",
    "    idx_val = torch.cat((majority[range_val_maj], minority[range_val_min]))\n",
    "    idx_train = torch.cat((majority[range_train_maj], minority[range_train_min]))\n",
    "    idx_train = torch.cat((idx_train, generate_node))\n",
    " \n",
    "    num_real = features.shape[0] - len(idx_test) -len(idx_val)\n",
    "\n",
    "    # Train model\n",
    "    model_generator.train()\n",
    "    optimizer_G.zero_grad()\n",
    "    z = Variable(torch.FloatTensor(np.random.normal(0, 1, (generate_node.shape[0], 100))))\n",
    "    if cuda:\n",
    "        z=z.cuda()\n",
    "\n",
    "    adj_min = model_generator(z)\n",
    "    gen_imgs1 = torch.mm(F.softmax(adj_min[:,0:minority.shape[0]], dim=1), features[minority])\n",
    "    gen_imgs1_all = torch.mm(F.softmax(adj_min, dim=1), features[minority_all])\n",
    "\n",
    "    matr = F.softmax(adj_min[:,0:minority.shape[0]], dim =1).data.cpu().numpy()\n",
    "    pos=np.where(matr>1/matr.shape[1])\n",
    "\n",
    "    adj_temp = sp.coo_matrix((np.ones(pos[0].shape[0]),(generate_node[pos[0]].numpy(), minority_all[pos[1]].numpy())),\n",
    "                             shape=(labels.shape[0], labels.shape[0]),\n",
    "                             dtype=np.float32)\n",
    "\n",
    "    adj_new = add_edges(adj_real, adj_temp)\n",
    "    if cuda:\n",
    "        adj_new=adj_new.cuda()\n",
    "\n",
    "    t_total = time.time()\n",
    "    # model.eval()\n",
    "    output, output_gen, output_AUC = model(torch.cat((features, gen_imgs1.data),0), adj)\n",
    "\n",
    "    labels_true = torch.LongTensor(num_false).fill_(0)\n",
    "    labels_min = torch.LongTensor(num_false).fill_(1)\n",
    "    if cuda:\n",
    "        labels_true = labels_true.cuda()\n",
    "        labels_min = labels_min.cuda()\n",
    "    #F.nll_loss(output_gen[generate_node], labels_true) \\ + F.nll_loss(output[generate_node], labels_min) \\\n",
    "    g_loss = F.nll_loss(output_gen[generate_node], labels_true) \\\n",
    "            + F.nll_loss(output[generate_node], labels_min) \\\n",
    "            + euclidean_dist(features[minority], gen_imgs1).mean()\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        test_recall, test_pre, test_f1, test_AUC, test_acc, confusion, t_loss = train(torch.cat((features, gen_imgs1.data.detach()),0), adj_new)\n",
    "\n",
    "    \n",
    "    print(\"g_loss=\".format(g_loss),\"Epoch:\", '%04d' % (epoch_gen + 1),\n",
    "        \"recall=\", \"{:.5f}\".format(test_recall), \"precision=\", \"{:.5f}\".format(test_pre),\"f1=\", \"{:.5f}\".format(test_f1), \"AUC=\", \"{:.5f}\".format(test_AUC), \"ACC=\", \"{:.5f}\".format(test_acc))\n",
    "    \n",
    "\n",
    "\n",
    "print()\n",
    "print('final_test')\n",
    "print()\n",
    "print(\"Test Recall: \", test_recall)\n",
    "print(\"Test Accuracy: \", test_acc)\n",
    "print(\"Test F1: \", test_f1)\n",
    "print(\"Test precision: \", test_pre)\n",
    "print(\"Test AUC: \", test_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10149, 80]) tensor([[0.3395, 0.0364, 0.2212,  ..., 0.2102, 0.2679, 0.2598],\n",
      "        [0.1764, 0.0568, 0.3672,  ..., 0.1314, 0.1526, 0.1064],\n",
      "        [1.8216, 0.0000, 0.0000,  ..., 1.0246, 1.3121, 1.4680],\n",
      "        ...,\n",
      "        [0.0000, 0.0781, 0.6537,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0783, 0.6546,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0784, 0.6545,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2980,  699, 1795, ..., 2052, 5331, 5548])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_generator = Generator(minority_all.shape[0])\n",
    "\n",
    "embedded = model.get_embedding(torch.cat((features, gen_imgs1.data),0), adj)\n",
    "\n",
    "\n",
    "\n",
    "print(embedded.shape, embedded)\n",
    "\n",
    "df = pd.DataFrame(embedded.detach().numpy())\n",
    "csv_filename = 'Imgagn-Embedding.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv for GANTAT)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
